% ------------------------------------------------------------------------------
\section{Introduction \note{1.5pp}}
\label{sec:intro}
% background: easy stuff
The task of parsing may be viewed as receiving a document in an
unstructured, or serialized, form, and building its structured
representation, equipped with an argument that the structured
representation is a faithful representation of the given document.
%
For formats defined in conventional data-description languages that
correspond closely to well-understood classes of the Chomsky hierarchy
(i.e., context-free grammars, with regular expressions as a critical
special case), trustworthy arguments fall out naturally from the
definition of the format itself.
%
This is in part due to the fact that in such formats, the structured
representation of a large segment of a message is defined purely in
terms of the structure of its segments.
%
E.g., the structure of a record consisting of multiple fields (e.g., a
name, age, and social security number) is defined in terms of the
correct structure of each of the constituent fields.

\todo{formats like PDF: semantic value is an object model, related data objects may not be serialized locally, relies on a notion of naming/reference}

\todo{further complications: data structures that define context may not be incremental, compressed}

\todo{option: say that processing and validating such objects is beyond the scope of parsing. Unappealing because there's a lot of validating of serialized data left to be done.}

\todo{this paper: in-depth case study of one key example of DOM parsing: parsing data structures relevant to the PDF DOM}

\subsection{PDF and its challenges}
\label{sec:pdf-challenges}

\begin{lstlisting}[style=meta]
- Creation of DOM ("document object model")
  - list of object definitions
  - ... containing object references
  - designated root object
- Cross-reference (xref) table
  - table with byte offset for each object
- Cross-reference streams (added in PDF 1.5) [7 pp. in spec]
  - compressed, complicated, space-efficient, ...
  - allows for hybrid files with both traditional
    xref tables and new xref streams
- Incremental updates
  - by only appending to PDF file we can add, update, delete, restore objects
- Linearized PDF (efficient incremental access) a.k.a. "Fast web view"
  - "differential by design"!
\end{lstlisting}

\begin{lstlisting}[style=meta]
- We must accurately create the DOM (a DAG, no cycles allowed)
  - ... while abstracting over xref tables, xref streams,
    hybrid files, incremental updates, linearization
  - ... while recovering from errors
  - ... while doing xref table reconstruction

- This is the source of errors, ambiguities, and vulnerabilities!
\end{lstlisting}

\subsection{PDF Vulnerabilities}
\label{sec:pdf-vulnerabilities}
\todo{here, briefly describe vulnerabilities, citing the literature,
  but not going into great detail.
  In \cref{sec:predom-vulnerabilities}
  we'll go into further detail on pre-DOM vulnerabilities.
}

\begin{lstlisting}[style=meta]
- Schizophrenic files
- Polyglot files
- [QUESTION: these last two common terms or ``Safedocs''-isms?]
- Shadow attacks: possible because of ability to sign dead objects and cavities
- Steganographic attacks (similar to Shadow)
- Multiple places for hidden/unused/malicious data in PDF
  - non-obvious places, unnoticed when "simply parsing"
  - e.g., shadow-attacks
  - dead bytes, dead objects, dead updates, dead linearization sections, etc.
\end{lstlisting}

\todo{Refer to these and others:
  pdf-insecurity.org publications,
  https://itextpdf.com/en/blog/technical-notes/investigating-pdf-shadow-attacks-depth-pdf-security-using-itext-part-3,
  K. Koptyra and M. R. Ogiela, “Distributed Steganography in PDF Files - Secrets Hidden in Modified Pages,” Entropy, vol. 22, no. 6, p. 600, May 2020, doi: 10.3390/e22060600.
}

\subsection{Summary of Paper}

\todo{in section 1 we ... blah, in section 2 blah, ... [Mark hates writing this useless paragraph]}