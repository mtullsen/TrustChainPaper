% ------------------------------------------------------------------------------
\section{Introduction}
\label{sec:intro}
% background: conventional grammars:
The task of parsing may be viewed as receiving a document in an
unstructured, serialized form, and building its structured
representation. Furthermore, this structured representation must be a
faithful representation of the given document.
%
For formats defined in conventional data-description languages that
correspond closely to well-understood classes of the Chomsky hierarchy
(i.e., context-free grammars, with regular expressions as a critical
special case), trustworthy arguments fall out naturally from the
definition of the format itself.
%
This is in part due to the fact that in such formats, the structured
representation of a large segment of a message is defined purely in
terms of the structure of its segments.

% real formats have DOMs, which involve names and references
However, these key properties regarding context-freedom of a
definition critically do not hold for many practical formats of
interest.
%
Many such formats define a \emph{Document Object Model}: i.e., the
result of parsing a document is a graph between objects, each
of which may store a large set of fields.
%
In such formats, it is infeasible to provide context-free definitions
of well-formedness because data objects that must satisfy critical
relations may not occur contiguously in a document: related objects
may not form a tree-like hierarchy in the input stream.
%
Such formats typically introduce a notion of \emph{naming} or
\emph{reference} by which objects may refer to each other.
%
A critical practical example of this design pattern---and the
motivating example of our work---is the document object model of the
\emph{Portable Document Format (PDF)}~\cite{isotc171sc2wg8ISO32000220202020};
%
PDF data objects include an \emph{object identifier}, by which other
objects may refer to them.

% further complications: people want to do other fancy tricks with
% context tables
In such formats, the structures of references and context take on
central importance.
%
In practice, their structure is quite complex in order to support
practical demands.
%
E.g., PDF's \emph{cross-reference tables} support
% 
\textbf{(1)} the interpretation of documents to be strongly mutated by
appending text, via \emph{incremental updates};
%
\textbf{(2)} reference structure to be compressed, via standardized
but non-trivial algorithms applied to \emph{cross-reference streams},
potentially combined with conventional cross-reference tables in
\emph{hybrid files}; and
% 
\textbf{(3)} large documents to be partially processed incrementally,
via \emph{linearization}.

% security consequences::
Difficulties in expressing the structure and semantics of references
continue to result in critical security vulnerabilities.
%
The may induce \emph{ambiguities}, which may cause different parties
to assign wildly different semantic interpretations to the same
document.
%
Recently discovered attacks that compromise the integrity and
usability of digital
signatures~\cite{rohlmannBreakingSpecificationPDF2021,
  mainkaShadowAttacksHiding2021} use maliciously crafted
cross-reference tables.
%
Document \emph{cavities}---segments of a document that are not
reflected in its semantic interpretation---may store content that is
completely unobservable to parser clients.
%
Such cavities are a powerful mechanism for creating \emph{polyglot
  files} (i.e., files that belong to multiple, unexpected formats),
which themselves have been used in recent critical system security
exploits~\cite{psychicPaper}.

% potential solutions and why they fail:
Context-free grammars are not suitable to define such formats in full
detail.
%
In the conventional setting, a parser returns a semantic value that is
then potentially transformed by further computation, which itself be
defined in an attribute grammar or parser client logic.
%
The main limitation of such an approach is that computation on
semantic values must then itself effectively parse unstructured data
after computing partial contextual information;
%
such parsing logic is exactly what should be expressed declaratively
in a grammar and implemented by a generated parser.

% our solution: very careful parser combinators:
This paper explores a third approach: parser combinators that include
constructs for explicitly capturing input and parsing a
previously-captured input, combined using computation on semantic
values in Haskell.
%
This approach is explored within an industrial strength case study:
validating and parsing the reference tables that are used to create 
an unambiguous and trustworthy PDF DOM.
%
We believe that our work is novel in aiming to formalize and model
this step in the PDF ``Trust Chain," and thus strongly complements all
efforts that rely on a trustworthy formalization of reference in order
to validate properties of higher-level document abstraction defined in
terms of the DOM.

% background on parser combinators:
In general, using parser combinators is not new: such combinators are
available widely available in the distributions of modern industrial
strength languages~\cite{leijen2001parsec,couprie2015nom,mundkurResearchReportParsley2020,bratus2017curing,willis2020staged}.
%
Moreover, with the recent interest in formalizing practical formats
and generating high-assurance parsers, such combinators have
specifically been applied to formalize components of the
PDF standard related to referential context.
%
However, our work is unique in that, to our knowledge, it constitutes
the first attempt to use such combinators to formalize a comprehensive
set of features and integrity relationships in PDF pre-DOM processing
that define referential context, specifically cross reference tables,
incremental updates, and cross reference table compression within
cross-reference streams. PDF is a random-access binary file format
that must be processed from the most recent (latest) incremental
update through earlier edits back to the original document.
%
PDF cross-reference data defines byte offsets from the start of the
file to the start byte for each PDF object. PDF object identifiers may
also not be unique, as incremental updates may redefine existing
objects, or reinstate objects that were previously marked as free
(unused).
%
Thus, in order to correctly establish a final PDF DOM graph, it is
necessary to process each appended incremental update in reverse
order.

% results:
Our case study shows that such features can by formalized effectively.
%
The resulting definition is more subtle than what may be often be
implemented by inspecting the PDF standard or many extant documents:
in the process of producing our definition, we raised several issues
with the current PDF standard which have been acknowledged and
addressed by the PDF Association and the ISO.
%
However, there is nothing in the format definition that requires the
specific language of combinators employed: a key goal of our work is
to provide this formalized definition as a worked case study, to be
vetted and improved upon using definitions in other experimental data
definition languages as they are developed.

% further applications:
\todo{claim something about analyses built on top of definition?}

\paragraph*{Organization} The rest of this paper is organized as
follows;
%
\Cref{sec:trust-chain} presents the ``Trust Chain,'' a key metaphor
for understanding the intricacies of PDF pre-DOM parsing;
%
\Cref{sec:pdf} reviews complexities and associated vulnerabilities in
the PDF format and its processors;
%
\Cref{sec:specifying} presents our specification of reference in
detail;
%
\Cref{sec:assessing} gives assessments our approach;
%
\Cref{sec:rel-work} reviews related work, and %
\Cref{sec:conclusion} concludes.

