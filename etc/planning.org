* TODO Administrative/Plans/Org
** NOTE Effort: 2wks
** TODO [#A] submit Trust Chain paper to Langsec
DEADLINE: <2022-02-07 Mon -30d>
** APPT meeting <2022-01-19 Wed 15:00-16:00>

- overleaf
- share
  - spec.hs
  - outline
- considering a gitlab-ext repo for _
  - overleaf creates repo
- any task allocations

** NOTE 2022-01-19 mtg notes

- BTW,
  Extends
- PW: pragmatism vs formalisms of model
- PW: ICC table at front
  - anything with abs/relative offsets
    - mpeg?
  - WH: discuss ICC
- Bill: "tone down Haskell" - any functional/monadic    
- wiki pages : ICC : Q&A??
  - https://wiki.pdfa.org/pages/viewpage.action?pageId=51839560
- https://pdf-issues.pdfa.org/32000-2-2020/clause07.html#H7.5.7
  
** TODO [#B] send a version to walt w for review
SCHEDULED: <2022-02-01 Tue>

Hi Walt,

Thanks for volunteering to review our paper. Let me know if you have any
problems accessing the overleaf doc
  https://www.overleaf.com/4642632342sfvgzqbjzxrm

Your input is appreciated in any and all forms
 - overleaf comments
 - \note{}'s in latex
 - big picture comments in email, etc
 - And if you want, for "obvious improvements," you can edit the doc!
   
In case it's useful, I also invited you to be a collaborator on the underlying
github repo https://github.com/mtullsen/TrustChainPaper/

Right now some parts are a little rough.  (I'm planning on putting 4 more days
into this and Bill and Peter are also contributing significantly.) So, your
choice: review now in it's rough form or wait another day to review a bit more
polished version :-).

It would be great to have your comments by end of day Friday.

Thanks!

- Mark

** 2022-02-01 meeting

- Agenda
  - disc. of outline/etc
  - finish going through the spec.hs / the section
  - for NLS: ask about the Ruhr CVE and reporting and _
  - add people for \todo's
  - who's doing what?

- task allocation
  - Bill: conclusion
  - Bill?: 
  - Peter:
  - Mark : finish up _
  - Mark : move Peters stuff from TC to _
  - ? : ?
        
- TODO
  - Trust Chain
    - make consistently "Trust Chain"
  - in principle: what is xref table!
    - gory details
  - II.
    - levels/phases/layers
    - 
  - 1.A & 1.B

- random notes   
  - ETSI - pdf signature process      
  - phase: _
  - ICC earlier
  - "current work in progress"
    
- Terms
  - partial differentials & schizophrenic files.
    - ambiguity!
  - file level/object level
  - polyglot
    - cavities
  - NEED FOR TERMINOLOGY

- contribs
  - terminology for PDF/etc
    
* DONE msg to team

- I did a little restructuring in the doc:
  - removed some sections
  - added new top level sections
    - PDF 
      - Structures
      - Vulnerabilities
      - Root Causes of PDF Complexity
    - Relevance to Other Formats

- current task allocation in the new structure:
  - Bill: Conclusion
  - Bill: Intro
    - (can we (want we) to fit in paragraphs on PDF challenges and vulnerabilities?)
  - Peter: III.A. PDF Structure
    - and other subsections in III?
  - Peter: V. Relevance to Other Formats
    - ICC Stuff here
  - Mark : move Peter's details from II.B to IV
  - Mark : finish up IV.
      
* TODO misc

\pwnote{"schizo" is a SafeDocs term I believe, both "schizo files" AND "schizo objects". Polyglot is definitely pre-SafeDocs.}

* WAIT citation for 'cavity' term?
* TODO MT comments

- parser combinators?
  
=======
- contribs
  - terminology
    
>>>>>>> Stashed changes
* TODO re writing
** DONE determine no of stages and fixup the relevant sections!

- stages (passes)
  #+begin_src 
    +-----------------------------------------------------+
    | 1. Find & parse header and trailer                  |<-- File
    +-----------------------------------------------------+
                       | offsets + ...
                       v
    +-----------------------------------------------------+
    | 2. Find & parse incremental updates                 |<-- File
    +-----------------------------------------------------+
                       | list of XRef maps
                       v
    +-----------------------------------------------------+
    | 3. Merge incremental updates                        |
    +-----------------------------------------------------+
                       | XRef map
                       v
    +-----------------------------------------------------+
    | 4. XRef map to object map (candidate DOM)           |
    |    1. Parse uncompressed objects                 <--+-- File
    |    2. Decode streams & preprocess Object Streams <--+-- File
    |    3. Resolve Type 2 references                  <--+-- File
    +-----------------------------------------------------+
                       | DOM (candidate)                      
                       v
    +-----------------------------------------------------+
    | 5. Validate candidate DOM                           |
    +-----------------------------------------------------+
                       | DOM (final)                                    
                       v
    +-----------------------------------------------------+
    | 6. Render DOM                                       |
    +-----------------------------------------------------+
                       | 
                       v
  #+end_src
           
- note when xref complete?
  
** TODO misc/old-ish
- ?? for the repetitious use of ``parsing and computation''
- challenge: figuring out how much detail to go into, e.g., xref
- the idiom
  - details (e.g., in PDF)
  - general principles
    - E.g., such as
      - cavities
      - trust-chain 
      - redundant-data [highlight]
        - E.g., Size, we don't want to *invisibly*
          null-out obj. nums > Size
      - file-offsets in format
      - schizophrenia / polyglot
      - limitations of informal (english) standards
   - at least 1 other example of the principle
   - ICC, etc.
   
** TODO get all the bibs filled in

** TODO add line numbers to (some) listings: adjust lstlisting!
** TODO spell-check
** TODO final review
** ----
** TODO [#C] resurrect dropped text on cavity tool

  - Tool for inspecting and checking PDF at the pre-DOM level:
    Created tool for exploring the DOM Antecedent structures
    as well as validating them (more than a
    PDF reader necessarily does).
    - Based on Galois's \todo{TA2} PDF parser, this tool can
      parse and validate each incremental update separately
      display "incremental updates," "incremental xref tables,"
      parsed objects, and cavities (bytes that are not used)
      validate that object definitions do not overlap (in their source bytes)

* TODO our spec (spec.hs)
** TODO [#A] fix spec: do we pass jmp everywhere that's needed?
SCHEDULED: <2022-02-03 Thu>

** NOTE [#A] overview of pDOM

#+begin_src haskell

    updates :: [(XRefRaw, TrailerDict)]

  {- combine updates into single, good map -}
     -- if things all out of order!
     -- if indirect length is in later update

    xref :: ObjInd `Map` (Offset :+: Type2Ref)

  {- for trad offsets: parse the top level defns, stop at "stream" keyword -}

    domPass1 :: ObjId `Map` (TopLevelDef_UnDecStm :+: Type2Ref)

  {- for all Streams: decode the streams -}

    domPass2 :: ObjId `Map` (TopLevelDef :+: Type2Ref)

  {- lookup (and parse) compressed objects (that are referenced in xref) -}

    domFinal :: ObjId `Map` TopLevelDef

#+end_src

** TODO [#A] regarding spec: file:spec.hs

- TODO enumerate 'constraints' (so you can refer to in spec)
  - no length stored in ObjStm
    - really a constraint about Length fields in streams!

- NOTE    
  - no effort to attempt trivial efficiency gains, e.g.,
    - "first" do streams w/ direct lengths, and later
    - do streams w/ indirect lengths
  - where do we have over-eagerness?
    - or, when an error could occur, to over-strictnes
    - use =validate= to       
  - we could be more efficient by splitting into two maps.
    - error messages simpler with one map
  - this is a spec
    - could evaluate sooner, but dangerous
    - how to evaluate implem?
      - if spec shows *all* errors
        - implem must show some?
        - ???

- Q. can spec.hs be *more* declarative?
  - laziness gets you a lot, makes more declarative
    - TODO :: think about how this works
  - no avoiding the dependencies and places of failure
  - currently
    - hiding std parsing
    - laziness
    - type-directed, gives clarity
      - and tells us sooner/easier when a problem!
          
- desiderata
  - get various behaviours from one implem
    - e.g., the above =validate=
    - strict/lazy maps:
      - And encode errors in value of Map
           
  - you would like to get small variances/modifications with small changes
  - you should be able to get *all* errors at each place of parallelism
    - e.g., the map
  - E.g.,
    - add =validate b= and if "--validate" flag set, we =assert(b)=

** TODO spec (N) compared to a more Dynamic (D) spec/implementation

- implementation /N/ (New, typed, static, unrecursive)
  - see file:spec.hs
  - Q. how much of spec/*.ddl needs to change?

- implementation /D/ (Dynamic)
  - same as spec.hs, until pDOM
  - harder to ensure efficiency??
    - need/require updates?
  - similar to existing code/implementation:
    - you have =derefId= command
      - very lazy & you only access/read what is needed
      - it calls itself recursively!
        - TODO :: add check for infinite loop
      - e.g., if a "dependent on DOM parser" (stream with indirect), 
        then immediately look that up and parse that, then return
      
  - NOTE, /D/ compared to implementation /N/     
    - it *IS* nicely lazy if you don't want to =derefId= all obj ids
      - doesn't parse unused ObjStms
      - TODO :: ...?
    - more efficient than /N/ (?)
      - each object goes from unparsed to fully parsed
      - directly follows references without needing to recurse over ObjId Map
      - but ... every derefId needs to check evaled/not
    - con :: as currently done in pdf-hs-driver, allows bad PDFs
      - not detecting length in ObjStm unless *required*
      - we might have a recursive situation that is "well-defined"
      - help to have a =derefLength= / =derefFromUncompressed=
        - more complicated than just this, because this won't catch error if we
          luck out and the length is already decoded.
    - con :: no parallel execution, no parallel error messages
    - con :: imperative
    - con :: no way to create a validator from. ?
            
  - TODO :: write sketch of code, esp. w/o daedalus hacks.
    - could you do this part exclusively in Hs?
    
- reasons for /N/ over /D/
  - want to parse everything and be done
  - want to *efficiently* parse all objects
  - want to know (sooner) that all objects parse and pre-Dom works.
  - want to be assured that the code terminates 
  - elegance/simplicity in all objects being in same state of "evaluation"
                                  
** TODO [#B] regarding spec: themes

- redundancies:
  - in presence of *any* redundancy
    - [due to design or to new versions of standard]
    - if we want to be very lazy
      - we want to do things *one* way (easier)
    - if we want to be safe
      - we do things both ways and verify the same
    - if we want to be exuberant/robust
      - try all ways until one is successful
    - so, is there a way to *capture* these redundancies?
      : validateRedundancy p1 p2 -- where these may use ... already parsed
    
- how lazy/dynamic to be?
  - "Allow" can just mean "Ignore" here
  - E.g.,
    - Allow broken xref tables that are 'dead' after a
      bunch of updates?
      - how broken?
    - allow broken xref entries if
      - updated
      - the object id is unused
        - is unused in final version
    - ETC, ETC!

- adaptibility/etc
  - have a validate/not flag
  - change the laziness
  - print first / print *all* errors
      
* TODO [#B] exploring topic/thesis/slant
*** topics / what we want to address in any of the below approaches

- concept of cavities
  - polyglots leverage!
    
- we can show shadow attacks as being an instance of a more general
  issue/vulnerability
  - these being ...
    
- concept of trust chain can be relevant even to monolithic sw
  - show examples of low-level problems undermining high-level constructs
    - PDF, ICC, <find others>
      
- Examples    
  - ICC
    - effectively the same thing, has index table
      - implementations don't enforce "4 byte alignment" [?]
    - "enforce no gaps" [in ICC spec, but not implemented]
    - in OS!
  - PDF
    - detail of these in PDF
  - Examples of others _

*** (A) potential paper topics

1. Principles for Securing Data Formats (generalizing/principles/_)
   - E.g., PDF, ICC, and <TBD>
   - Principles/Generalizations
     - cavities
     - ambiguities
     - trust chain (dependencies for safety)
   - Specific attacks
     - shadow attacks
     - polyglots
     - ...  
    
2. The concept of trust chain for monolithic software
   - helps one to focus on 
     - most important vulnerabilities
     - a limited part of codebase
   - PDF a good example, thus the prime example for this paper

3. A taxonomy of low level PDF vulnerabilities
   - [i.e., an experience report for this work]
   - bill
     - problms: why nasty
     - why not yacc/bison
     - clear that we terminate (even with )
     - daedalus
       - parameterized rules & maps
     - _
   - ?
                  
4. real-world parsing (conceptual overview of PDF challenges)
   - [title: "parsing vs PARSING"]
   - PDF vs simpler formats
   - not just "sequence/choice/bind" but
     - parallelism
     - set-input-at
     - parse result of parse
     - redundant "parsing methods" [word for?] {A,B} giving many choices:
       : A, B, A `thenTry` B, B `thenTry` A, parseBothCheckIdentical A B
       - parse A, process with B
         
     - significant/complex computation required "in the midst" of basic
       computation (_)
     - ? : the recursive object stream thing: where there are circular
       dependencies among objects in same type.

   - NOTE, both
     - more complex than typical data formats
     - more complex, in some ways, than Programming Language parsing

*** (B) potential paper topics

1. Categorizing parsers 
   - [more theoretical]
   - PL concepts
     - lattice of parser definedness
     - projections
   - useful for ...
    
2. cavities, a concept for understanding PDFs (and _)
   - 

* ---- history/ref ----
* DONE biblio

If you're interested in browsing the citations and having the CITEKEYS at hand, do what I did:
I installed Better BibTex in my Zotero *App*, see this
 https://retorque.re/zotero-better-bibtex/installation/
Leave the citekeys as default as they note
  "the default setting of BBT will generate different citekeys than Zotero"
You don't need to export, as ...
I exported all 597 references in PDF to zotero-pdf-biblio.bib (now in the repo).

See my screen shot,
your Citation Keys should be identical to mine, and you should be good to use Zotero to insert Citation Keys.
Peter, to cite that first paper, you would just put this in the latex:
  \cite{mladenovTrillionDollarRefund2019}

