* Settings                                                         :noexport:

#+TITLE: Strengthening Weak Links in the PDF Trust Chain
#+AUTHOR: Mark Tullsen, William Harris, Peter Wyatt
#+Email: tullsen@galois.com, wrharris@galois.com, peter.wyatt@pdfa.org

#+LaTeX_CLASS: beamer
% #+LATEX_CLASS_OPTIONS: [presentation,t]
% #+LATEX_CLASS_OPTIONS: [presentation,10pt]
% #+LATEX_CLASS_OPTIONS: [draft]
#+LATEX_CLASS_OPTIONS: [t,10pt,xcolor={dvipsnames}]
#+BEAMER_THEME: Madrid
#+BEAMER_FRAME_LEVEL: 1

#+COLUMNS: %45ITEM %10BEAMER_ENV(Env) %10BEAMER_ACT(Act) %4BEAMER_COL(Col) %8BEAMER_OPT(Opt)

#+OPTIONS: with-todo-keywords:t
% #+OPTIONS: H:1 toc:nil num:t tags:nil
#+OPTIONS:   H:1 num:t toc:nil \n:nil @:t ::t |:t ^:nil -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:nil skip:nil d:nil todo:nil pri:nil tags:nil
#+OPTIONS:   author:t inline:t

#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
% #+STARTUP: fninline

#+LATEX_HEADER: \AtBeginSection[]{\begin{frame}<beamer>\frametitle{}\tableofcontents[currentsection]\end{frame}}
#+LATEX_HEADER: \definecolor{Orange}{rgb}{1,0.5,0}
%  #+LATEX_HEADER: \include{prelude-slides}
#+LATEX_HEADER: \usepackage{listings}

% having no luck: !
% #+LATEX_HEADER: \usepackage{pgfpages}
% #+LATEX_HEADER: \setbeameroption{show notes}
% #+LATEX_HEADER: \setbeameroption{hide notes} % Only slides
% #+LATEX_HEADER: \setbeameroption{show only notes} % Only notes
% #+LATEX_HEADER: \setbeameroption{show notes on second screen=left} % Both

* TODO items/meta                                                  :noexport:

- NOTE
  - 10 mins (Research reports: the total is 15 mins including Q&A)
  - around 10 slides!

- determine what's in/out  
  - parser/validator slides
    - BTW: the standard is effectively defining a validator
      - no guidance as to how to write a robust parser
  - shotgun and APIs!  *A*
  - stage 4 Explanation.
  - [-] haskell code/types? no

- orphans/say
  - with daedalus ddl: spoiled, but you have *lots* of computation!   
  - our paper describes
    - an efficient and purely functional approach
      
# A     
- [ ] code listings: stage 4 and elsewhere
- [ ] bring in text/notes from other instantiations of talk

# B 
- [ ] emails on title page
- [ ] spell check
- [ ] practice 3x
  - some you've never given: Stage 4
      
* DONE example/motivation                                          :noexport:

- [x] how to create the diagram?
  - inkscape
    - bite the bullet: kinda tedious!
  - keynote  *YES*
  - ppt (install ms office!)
  - google doc and
    
- 
  | ObjId | XRef    | 4.1 result             | 4.2 result     | 4.3 |
  |-------+---------+------------------------+----------------+-----|
  | 3 0   | Ty1 100 | Ty1: IntObj 99         |                |     |
  | 4 0   | Ty2 5 1 | Ty2: 5 1               |                |  V2 |
  | 5 0   | Ty1 151 | ObjStm p-DICT u-STREAM | ObjStm [V1,V2] |     |

      ...
100   3 0 obj 99 endobj
123   % object 4 is not here
151   5 0 obj
      <<
      /Type /ObjStm
      /Length 3 0 R   % indirect!
      /N 2            % 2 objects; (potentially indirect)
      /First 10       % offset to 1st object (potentially indirect)
      >>
      stream
      4 0 6 100
      V1 % PDF-Value here, R 4 0, [fake comment] 
      V2 % PDF-Value here, R 6 0, [fake comment]
      endstream
      endobj
409   7 0 obj ... endobj
      ...

# ------------

5 0 obj
  << /Length 96 /Filter /FlateDecode >>
  stream
  endstream
  endobj  

* DONE PDF Complexity?

#+begin_export latex
\begin{center}
 { \hspace{5pt}
   \includegraphics[width=0.4\linewidth]{../figures/pdf-structure.png}
 } \hspace{30pt}
 \raisebox{-1\baselineskip}
          {\includegraphics[width=0.30\linewidth]{../figures/pdf-structure-incremental.png}}
\end{center}
#+end_export

* DONE PDF Trust Chain

#+begin_export latex
\begin{center}
\includegraphics[width=0.47\linewidth]{../figures/Stages.png}
\end{center}
#+end_export

* DONE Vulnerabilities Occurring Primarily at the Pre-DOM levels

- Schizophrenic files
- Polyglot files
- Shadow attacks: possible because of ability to sign
  *dead objects* and *cavities*
- Multiple places for hidden/unused/malicious data in PDF
  - non-obvious places, unnoticed when "simply parsing"
  - e.g., shadow-attacks
  - dead bytes, dead objects, dead updates, dead linearization sections, etc.

* DONE Challenges to Creating Correct and Trustworthy Pre-DOM 'Code'

- Lack of formality in standard. Thus, implementations:
  - are more effort
  - over implement, under implement, wrongly implement
- No definition of acceptable, reasonable error recovery
- Less than ideal design that reflects 27 years of an evolving standard
- Pre-DOM processing
  - is where many parsing errors & recovery occur
  - is non-trivial
  - involves multiple interdependent features
  - involves multiple redundant features
    - schizophrenic if these features aren't mutually consistent
      
* DONE Stage 4: Transform XRef Map to Object Map

#+begin_export latex
\begin{center}
\includegraphics[width=0.8\linewidth]{images/diagram1/cropped-diagram1.001.png}
\end{center}
#+end_export
#+begin_src bash
      ...
100   3 0 obj 99 endobj
123   % object 4 is not here
151   5 0 obj
      <<
      /Type /ObjStm
      /Length 3 0 R   % indirect!
      /N 2            % 2 objects; (potentially indirect)
      /First 10       % offset to 1st object (potentially indirect)
      >>
      stream
      4 0 6 100
      V1 % PDF-Value here, 4 0 R, [fake comment] 
      V2 % PDF-Value here, 6 0 R, [fake comment]
      endstream
      endobj
409   7 0 obj ... endobj
      ...
#+end_src

* TODO [#D] Specification Issue [Update the above]
* TODO [#C] Parser vs Validator
* TODO [#C] Implementation?

*[TODO: in the paper we note that we have, from scratch,
specified the hard parts but have not linked to our [daedalus generated]
primitive parsers]*

Tools & renderers rarely need (/demand/) the whole PDF
 - reading?
 - parsing??
 - semantic checks???
#+latex: \vspace{12pt}
   
Thus, this
#+begin_src haskell
  parsePDF :: FileData -> Maybe PDFAbstractSyntax
#+end_src
is not going to be used in practice!     

# Alternatives?

* TODO [#C] One Solution ...

- For complex formats,
  - tools are "projections": rarely to parse/validate all.
  - may have alternate "parsing paths" we want to take

- Shotgun Parsers?
  - ... the deadliest of patterns: "Input data checking, handling interspersed
    with processing logic"
- I.e., we provide multiple parsers where the following is interspersed through
  code and the relation between these is *not specified*:
  #+begin_src haskell
    parseA :: Offset -> IO A
    parseB :: Offset -> IO B
    parseC :: Offset -> IO C
    validateA :: A -> IO ()
    validateB :: A -> B -> IO ()
  #+end_src

* TODO [#C] Better Solution, Parser as API

We provide four interdependent calls (not /entry points/):
#+begin_src haskell
  parseHdrTrlr :: FileData -> IO HdrTrlr
  parseUpdates :: HdrTrlr -> IO [Updates]
  createXRef   :: [Updates] -> IO XRef
  derefObjId   :: ObjId -> XRef -> IO PdfValue
#+end_src
(Types can be as abstract as we wish.)

#+latex: \vspace{18pt}
Using this, we write abstractions on the above:
#+begin_src haskell
  getInitialUpdate :: FileData -> IO XRef
  getRootValue     :: HdrTrailer -> XRef -> PdfValue
  getPageTree      :: XRef -> Tree PdfValue
#+end_src

# https://darkbazaar.wordpress.com/category/researchers/bratus-sergey/
# 
#   Sadly, a lot of actual input handling code is a mixture of data processing
#   and recognition, scattered throughout a codebase. Its “sanity checking” is
#   neither strong enough to verify all the implicit assumptions, nor written
#   with these assumptions in mind. We call such input handling code “shotgun
#   parsers” and argue that it’s the number 1 reason for the ubiquitous
#   insecurity of programs facing the internet.

* TODO Conclusion
